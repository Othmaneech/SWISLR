{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm scidownl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_multi_papers():\n",
    "    \"\"\"Example of downloading multiple papers.\n",
    "    All papers will be downloaded to the ./paper/ directory,\n",
    "    and their filenames are the paper titles.\n",
    "    \"\"\"\n",
    "    source = [\n",
    "        (\"https://doi.org/10.1145/3375633\", 'doi', \"./paper/\"),\n",
    "        (\"31395057\", 'pmid', \"./paper/\"), \n",
    "        (\"24686414\", 'pmid', \"./paper/\"),\n",
    "        (\"Aggregated Residual Transformations for Deep Neural Networks\", 'title', \"./paper/\"),\n",
    "    ]\n",
    "    for paper, paper_type, out in source:\n",
    "        scihub_download(paper, paper_type=paper_type, out=out)\n",
    "\n",
    "#(\"https://doi.org/10.1145/3375633\", 'doi', \"./paper/\")\n",
    "#three options 1. (doi,'doi',./export location) 2.(pmid, 'pmid', ./export location) 3.(title, 'title',./paper/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scihub_download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m download_multi_papers()\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mdownload_multi_papers\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m source \u001b[39m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mhttps://doi.org/10.1145/3375633\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdoi\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m./paper/\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39m31395057\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpmid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m./paper/\u001b[39m\u001b[39m\"\u001b[39m), \n\u001b[1;32m      9\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39m24686414\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpmid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m./paper/\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mAggregated Residual Transformations for Deep Neural Networks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m./paper/\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m paper, paper_type, out \u001b[39min\u001b[39;00m source:\n\u001b[0;32m---> 13\u001b[0m     scihub_download(paper, paper_type\u001b[39m=\u001b[39mpaper_type, out\u001b[39m=\u001b[39mout)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scihub_download' is not defined"
     ]
    }
   ],
   "source": [
    "download_multi_papers()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "doi = \"/10.1016/j.envexpbot.2020.104254\"\n",
    "doi = \"10.1007/s10021-021-00686-w\"\n",
    "\n",
    "doi = doi.replace(':', '/')\n",
    "base_url = \"https://sci-hub.ru\"\n",
    "url = f\"{base_url}/{doi}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "try:\n",
    "    pdf_relative_url = soup.find('embed', {'type': 'application/pdf'}).get('src')\n",
    "except:\n",
    "    print(\"Nothing :(\")\n",
    "\n",
    "pdf_url = urljoin(base_url, pdf_relative_url)\n",
    "\n",
    "pdf_response = requests.get(pdf_url)\n",
    "\n",
    "\n",
    "filename = f\"data/{doi.replace('/', ':')}.pdf\"\n",
    "\n",
    "with open(filename, \"wb\") as file:\n",
    "    file.write(pdf_response.content)\n",
    "\n",
    "print(\"PDF downloaded successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
