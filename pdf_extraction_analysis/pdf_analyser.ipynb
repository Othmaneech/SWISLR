{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfminer\n",
    "# !pip install tqdm\n",
    "# !pip install python-time\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boilerplat Function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_file_content(path_to_pdf):\n",
    "    # Set parameters \n",
    "    out_text = StringIO()\n",
    "    text_converter = TextConverter(PDFResourceManager(caching=True), out_text, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(PDFResourceManager(caching=True), text_converter)\n",
    "\n",
    "    fp = open(path_to_pdf, 'rb')\n",
    "\n",
    "    # Set the maximum number of pages to read\n",
    "    max_pages = 7\n",
    "\n",
    "    # Use tqdm to create a progress bar\n",
    "    # with tqdm(total=max_pages, desc=\"Extracting\") as pbar:\n",
    "    for index, page in enumerate(PDFPage.get_pages(fp, pagenos=set())):\n",
    "        interpreter.process_page(page)\n",
    "        # pbar.update(1)\n",
    "\n",
    "        # Check if the maximum number of pages has been reached\n",
    "        if index + 1 >= max_pages:\n",
    "            break\n",
    "\n",
    "    text = out_text.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    text_converter.close()\n",
    "    out_text.close()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_newlines(text):\n",
    "    # Replace newlines in the middle of a sentence with spaces\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "\n",
    "    # Remove newlines at the end of a sentence\n",
    "    text = re.sub(r'\\n$', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def most_recurrent_locations(text: str) -> dict:\n",
    "    # Load the pre-trained model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Replace newlines in the text\n",
    "    sample_text = replace_newlines(text)\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(sample_text)\n",
    "\n",
    "    # Find location words and their locations\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == \"GPE\" or entity.label_ == \"LOC\"]\n",
    "\n",
    "    # Disregard strings that contain specific words\n",
    "    disregarded_words = ['USA', 'United States', 'United States of America', 'North America', 'UNITED STATES', 'al.', 'US', \"U.S.\", 'the United States']\n",
    "    locations = [location for location in locations if not any(word in location for word in disregarded_words)]\n",
    "\n",
    "    # Count the frequency of each location\n",
    "    location_counts = Counter(locations)\n",
    "\n",
    "    # Sorting locations by frequency\n",
    "    sorted_locations = sorted(location_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Create a dictionary with 7 item (frequency) format\n",
    "    first_elements = {f\"{item} ({count})\": count for item, count in sorted_locations[:7]}\n",
    "\n",
    "    return first_elements\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pdf_file_names():\n",
    "    pdf_files = glob.glob(\"data/*.pdf\")\n",
    "    return pdf_files\n",
    "\n",
    "# Define a function to process a single file\n",
    "def process_pdf_file(file):\n",
    "    content = get_pdf_file_content(file)\n",
    "    output_dict = most_recurrent_locations(content)\n",
    "    return file, list(output_dict.keys())\n",
    "\n",
    "pdf_files = get_pdf_file_names()\n",
    "list_of_lists = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:36<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "filename = []\n",
    "# Create a ThreadPoolExecutor with the maximum number of worker threads\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit the file processing tasks to the executor\n",
    "    future_results = [executor.submit(process_pdf_file, file) for file in pdf_files]\n",
    "\n",
    "    # Use tqdm to track the progress of the tasks\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_results), total=len(future_results)):\n",
    "        # Retrieve the result from the completed task and append it to the list\n",
    "        list_of_lists.append(future.result()[1])\n",
    "        filename.append(future.result()[0])\n",
    "\n",
    "# Find the maximum number of elements in the lists\n",
    "max_list_length = max(len(lst) for lst in list_of_lists)\n",
    "\n",
    "# Add empty strings to lists lacking elements\n",
    "for lst in list_of_lists:\n",
    "    while len(lst) < max_list_length:\n",
    "        lst.append('')\n",
    "\n",
    "# Now all the lists inside list_of_lists have the same number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = []\n",
    "# list_of_lists = []\n",
    "\n",
    "# # Process each file sequentially\n",
    "# for file in pdf_files:\n",
    "#     result = process_pdf_file(file)\n",
    "#     list_of_lists.append(result[1])\n",
    "#     filename.append(result[0])\n",
    "\n",
    "# # Find the maximum number of elements in the lists\n",
    "# max_list_length = max(len(lst) for lst in list_of_lists)\n",
    "\n",
    "# # Add empty strings to lists lacking elements\n",
    "# for lst in list_of_lists:\n",
    "#     while len(lst) < max_list_length:\n",
    "#         lst.append('')\n",
    "\n",
    "\n",
    "# pdf_files = glob.glob(\"PDF Papers (20)/*.pdf\")\n",
    "# file = pdf_files[0]\n",
    "# text_file = open(\"sample.txt\", \"w\")\n",
    "# n = text_file.write(get_pdf_file_content(file))\n",
    "# text_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'list_of_lists' now contains the results from processing each PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the West Coast (1)', 'Florida (1)', 'San Bernardino (1)', '', '', '', ''],\n",
       " ['L-1 (10)',\n",
       "  'Biogeochemistry (4)',\n",
       "  'North Carolina (3)',\n",
       "  'NC (2)',\n",
       "  'Columbia (2)',\n",
       "  'MD (2)',\n",
       "  'N2O (1)'],\n",
       " ['North Carolina (4)',\n",
       "  'Gull Rock (3)',\n",
       "  'Swanquarter (3)',\n",
       "  'Swanquar- (2)',\n",
       "  'Palmetto Peartree Preserve (2)',\n",
       "  '0.01b (2)',\n",
       "  'Raleigh (1)'],\n",
       " ['North Carolina (4)',\n",
       "  'Biogeochemistry (4)',\n",
       "  'the Albemarle Sound (4)',\n",
       "  'NC (3)',\n",
       "  'L-1 (3)',\n",
       "  'Ardo´n (2)',\n",
       "  'Ohio (2)'],\n",
       " ['North Carolina (8)',\n",
       "  'Bhattachan (3)',\n",
       "  'North  Carolina (3)',\n",
       "  'Haywood (2)',\n",
       "  'Netherlands (2)',\n",
       "  'the Albemarle Sound (2)',\n",
       "  'ArcGIS (2)'],\n",
       " ['Maryland (9)',\n",
       "  'New York (7)',\n",
       "  'Virginia (7)',\n",
       "  'Florida (6)',\n",
       "  'New Brunswick (4)',\n",
       "  'KEARNEY (4)',\n",
       "  'Copenheaver (3)'],\n",
       " ['the Altamaha River (7)',\n",
       "  'HS(cid:1 (4)',\n",
       "  'N (4)',\n",
       "  'Georgia (3)',\n",
       "  'Canfield (3)',\n",
       "  'Weston (2)',\n",
       "  'Altamaha River (2)'],\n",
       " ['Smith (7)',\n",
       "  'New Jersey (6)',\n",
       "  'the Delaware Bay (4)',\n",
       "  'Sebold (4)',\n",
       "  'Delaware (3)',\n",
       "  'Weishar (3)',\n",
       "  'Warren (3)'],\n",
       " ['Louisiana (13)',\n",
       "  'South Carolina (12)',\n",
       "  'Georgia (10)',\n",
       "  'Waccamaw (5)',\n",
       "  'Waccamaw River (2)',\n",
       "  'Winyah Bay (2)',\n",
       "  'Savannah River (2)'],\n",
       " ['NS (14)',\n",
       "  'NaCl (6)',\n",
       "  'Specifi (2)',\n",
       "  'MD (2)',\n",
       "  'NS\\n\\n (2)',\n",
       "  'NS NS (2)',\n",
       "  'Purvaja (2)'],\n",
       " ['New England (9)',\n",
       "  'Niering (8)',\n",
       "  'Warren (8)',\n",
       "  'C.R. (7)',\n",
       "  'Connecticut (7)',\n",
       "  'Smith (4)',\n",
       "  'C.S. (4)'],\n",
       " ['North Carolina (4)',\n",
       "  'HUC (4)',\n",
       "  'Louisiana (3)',\n",
       "  'Gulf (2)',\n",
       "  'Landsat (2)',\n",
       "  'Akaike (2)',\n",
       "  'Charlottesville (1)'],\n",
       " ['North Carolina (10)',\n",
       "  'North  Carolina (7)',\n",
       "  'North Carolina’s (3)',\n",
       "  'NC (3)',\n",
       "  'Battaglia (3)',\n",
       "  'Coastal Plain (3)',\n",
       "  'Liquidambar (3)'],\n",
       " ['North Carolina (7)',\n",
       "  'Bird (2)',\n",
       "  'the Albemarle Sound (1)',\n",
       "  'the Croatan Sound (1)',\n",
       "  'the Pamlico Sound (1)',\n",
       "  'the Neuse River (1)',\n",
       "  'Blue Grosbeak (1)'],\n",
       " ['Sorghum (13)',\n",
       "  'Maryland (7)',\n",
       "  'Tester (7)',\n",
       "  'Kielen (7)',\n",
       "  'Tanji (6)',\n",
       "  'MD (4)',\n",
       "  'Qadir (3)'],\n",
       " ['L-1 (5)',\n",
       "  'Weston (4)',\n",
       "  'North Carolina (3)',\n",
       "  'N2O (3)',\n",
       "  'California (2)',\n",
       "  'Mason (2)',\n",
       "  'Ohio (2)'],\n",
       " ['Weston (5)',\n",
       "  'Bridgham (3)',\n",
       "  'South Carolina (2)',\n",
       "  'Richmond (2)',\n",
       "  'Virginia (2)',\n",
       "  'the Waccamaw River (2)',\n",
       "  'Waccamaw River (2)'],\n",
       " ['Florida (15)',\n",
       "  'Louisiana (14)',\n",
       "  'Mississippi (10)',\n",
       "  'Texas (8)',\n",
       "  'Gulf of Mexico (8)',\n",
       "  'LA (8)',\n",
       "  'Alabama (6)']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Making Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Remove \"PDF Papers (20)\" from the strings in pdf_files\n",
    "filename = [file.replace(\"PDF Papers (20)/\", \"\") for file in filename]\n",
    "\n",
    "# Extract the columns from list_of_lists\n",
    "col1 = [item[0] if len(item) > 0 else '' for item in list_of_lists]\n",
    "col2 = [item[1] if len(item) > 1 else '' for item in list_of_lists]\n",
    "col3 = [item[2] if len(item) > 2 else '' for item in list_of_lists]\n",
    "col4 = [item[3] if len(item) > 3 else '' for item in list_of_lists]\n",
    "col5 = [item[4] if len(item) > 4 else '' for item in list_of_lists]\n",
    "col6 = [item[5] if len(item) > 5 else '' for item in list_of_lists]\n",
    "col7 = [item[6] if len(item) > 6 else '' for item in list_of_lists]\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'PDF File': filename,\n",
    "    'Col1': col1,\n",
    "    'Col2': col2,\n",
    "    'Col3': col3,\n",
    "    'Col4': col4,\n",
    "    'Col5': col5,\n",
    "    'Col6': col6,\n",
    "    'Col7': col7\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDF File</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEA-LEVEL RISE AND COASTAL FOREST RETREAT ON T...</td>\n",
       "      <td>the West Coast (1)</td>\n",
       "      <td>Florida (1)</td>\n",
       "      <td>San Bernardino (1)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1007:s10533-014-9986-x.pdf</td>\n",
       "      <td>L-1 (10)</td>\n",
       "      <td>Biogeochemistry (4)</td>\n",
       "      <td>North Carolina (3)</td>\n",
       "      <td>NC (2)</td>\n",
       "      <td>Columbia (2)</td>\n",
       "      <td>MD (2)</td>\n",
       "      <td>N2O (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1007:s10533-021-00797-5.pdf</td>\n",
       "      <td>North Carolina (4)</td>\n",
       "      <td>Gull Rock (3)</td>\n",
       "      <td>Swanquarter (3)</td>\n",
       "      <td>Swanquar- (2)</td>\n",
       "      <td>Palmetto Peartree Preserve (2)</td>\n",
       "      <td>0.01b (2)</td>\n",
       "      <td>Raleigh (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1007:s10533-016-0189-5.pdf</td>\n",
       "      <td>North Carolina (4)</td>\n",
       "      <td>Biogeochemistry (4)</td>\n",
       "      <td>the Albemarle Sound (4)</td>\n",
       "      <td>NC (3)</td>\n",
       "      <td>L-1 (3)</td>\n",
       "      <td>Ardo´n (2)</td>\n",
       "      <td>Ohio (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1007:s11069-019-03706-0.pdf</td>\n",
       "      <td>North Carolina (8)</td>\n",
       "      <td>Bhattachan (3)</td>\n",
       "      <td>North  Carolina (3)</td>\n",
       "      <td>Haywood (2)</td>\n",
       "      <td>Netherlands (2)</td>\n",
       "      <td>the Albemarle Sound (2)</td>\n",
       "      <td>ArcGIS (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.2112:04-0211.1.pdf</td>\n",
       "      <td>Maryland (9)</td>\n",
       "      <td>New York (7)</td>\n",
       "      <td>Virginia (7)</td>\n",
       "      <td>Florida (6)</td>\n",
       "      <td>New Brunswick (4)</td>\n",
       "      <td>KEARNEY (4)</td>\n",
       "      <td>Copenheaver (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1029:2005JG000071.pdf</td>\n",
       "      <td>the Altamaha River (7)</td>\n",
       "      <td>HS(cid:1 (4)</td>\n",
       "      <td>N (4)</td>\n",
       "      <td>Georgia (3)</td>\n",
       "      <td>Canfield (3)</td>\n",
       "      <td>Weston (2)</td>\n",
       "      <td>Altamaha River (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1016:j.ocecoaman.2017.09.010.pdf</td>\n",
       "      <td>Smith (7)</td>\n",
       "      <td>New Jersey (6)</td>\n",
       "      <td>the Delaware Bay (4)</td>\n",
       "      <td>Sebold (4)</td>\n",
       "      <td>Delaware (3)</td>\n",
       "      <td>Weishar (3)</td>\n",
       "      <td>Warren (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1672:08-77.1.pdf</td>\n",
       "      <td>Louisiana (13)</td>\n",
       "      <td>South Carolina (12)</td>\n",
       "      <td>Georgia (10)</td>\n",
       "      <td>Waccamaw (5)</td>\n",
       "      <td>Waccamaw River (2)</td>\n",
       "      <td>Winyah Bay (2)</td>\n",
       "      <td>Savannah River (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.2136:sssaj2011.0026.pdf</td>\n",
       "      <td>NS (14)</td>\n",
       "      <td>NaCl (6)</td>\n",
       "      <td>Specifi (2)</td>\n",
       "      <td>MD (2)</td>\n",
       "      <td>NS\\n\\n (2)</td>\n",
       "      <td>NS NS (2)</td>\n",
       "      <td>Purvaja (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.1016:j.biocon.2016.07.035.pdf</td>\n",
       "      <td>New England (9)</td>\n",
       "      <td>Niering (8)</td>\n",
       "      <td>Warren (8)</td>\n",
       "      <td>C.R. (7)</td>\n",
       "      <td>Connecticut (7)</td>\n",
       "      <td>Smith (4)</td>\n",
       "      <td>C.S. (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.1007:s10021-021-00686-w.pdf</td>\n",
       "      <td>North Carolina (4)</td>\n",
       "      <td>HUC (4)</td>\n",
       "      <td>Louisiana (3)</td>\n",
       "      <td>Gulf (2)</td>\n",
       "      <td>Landsat (2)</td>\n",
       "      <td>Akaike (2)</td>\n",
       "      <td>Charlottesville (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.1093:aob:mcz039.pdf</td>\n",
       "      <td>North Carolina (10)</td>\n",
       "      <td>North  Carolina (7)</td>\n",
       "      <td>North Carolina’s (3)</td>\n",
       "      <td>NC (3)</td>\n",
       "      <td>Battaglia (3)</td>\n",
       "      <td>Coastal Plain (3)</td>\n",
       "      <td>Liquidambar (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.1371:journal.pone.0216540.pdf</td>\n",
       "      <td>North Carolina (7)</td>\n",
       "      <td>Bird (2)</td>\n",
       "      <td>the Albemarle Sound (1)</td>\n",
       "      <td>the Croatan Sound (1)</td>\n",
       "      <td>the Pamlico Sound (1)</td>\n",
       "      <td>the Neuse River (1)</td>\n",
       "      <td>Blue Grosbeak (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.1016:j.envexpbot.2020.104254.pdf</td>\n",
       "      <td>Sorghum (13)</td>\n",
       "      <td>Maryland (7)</td>\n",
       "      <td>Tester (7)</td>\n",
       "      <td>Kielen (7)</td>\n",
       "      <td>Tanji (6)</td>\n",
       "      <td>MD (4)</td>\n",
       "      <td>Qadir (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.1007:s10021-018-0325-2.pdf</td>\n",
       "      <td>L-1 (5)</td>\n",
       "      <td>Weston (4)</td>\n",
       "      <td>North Carolina (3)</td>\n",
       "      <td>N2O (3)</td>\n",
       "      <td>California (2)</td>\n",
       "      <td>Mason (2)</td>\n",
       "      <td>Ohio (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.5194:bg-10-8171-2013.pdf</td>\n",
       "      <td>Weston (5)</td>\n",
       "      <td>Bridgham (3)</td>\n",
       "      <td>South Carolina (2)</td>\n",
       "      <td>Richmond (2)</td>\n",
       "      <td>Virginia (2)</td>\n",
       "      <td>the Waccamaw River (2)</td>\n",
       "      <td>Waccamaw River (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.1111:1365-2664.13169.pdf</td>\n",
       "      <td>Florida (15)</td>\n",
       "      <td>Louisiana (14)</td>\n",
       "      <td>Mississippi (10)</td>\n",
       "      <td>Texas (8)</td>\n",
       "      <td>Gulf of Mexico (8)</td>\n",
       "      <td>LA (8)</td>\n",
       "      <td>Alabama (6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             PDF File                    Col1  \\\n",
       "0   SEA-LEVEL RISE AND COASTAL FOREST RETREAT ON T...      the West Coast (1)   \n",
       "1                       10.1007:s10533-014-9986-x.pdf                L-1 (10)   \n",
       "2                      10.1007:s10533-021-00797-5.pdf      North Carolina (4)   \n",
       "3                       10.1007:s10533-016-0189-5.pdf      North Carolina (4)   \n",
       "4                      10.1007:s11069-019-03706-0.pdf      North Carolina (8)   \n",
       "5                               10.2112:04-0211.1.pdf            Maryland (9)   \n",
       "6                            10.1029:2005JG000071.pdf  the Altamaha River (7)   \n",
       "7                 10.1016:j.ocecoaman.2017.09.010.pdf               Smith (7)   \n",
       "8                                 10.1672:08-77.1.pdf          Louisiana (13)   \n",
       "9                          10.2136:sssaj2011.0026.pdf                 NS (14)   \n",
       "10                   10.1016:j.biocon.2016.07.035.pdf         New England (9)   \n",
       "11                     10.1007:s10021-021-00686-w.pdf      North Carolina (4)   \n",
       "12                             10.1093:aob:mcz039.pdf     North Carolina (10)   \n",
       "13                   10.1371:journal.pone.0216540.pdf      North Carolina (7)   \n",
       "14                10.1016:j.envexpbot.2020.104254.pdf            Sorghum (13)   \n",
       "15                      10.1007:s10021-018-0325-2.pdf                 L-1 (5)   \n",
       "16                        10.5194:bg-10-8171-2013.pdf              Weston (5)   \n",
       "17                        10.1111:1365-2664.13169.pdf            Florida (15)   \n",
       "\n",
       "                   Col2                     Col3                   Col4  \\\n",
       "0           Florida (1)       San Bernardino (1)                          \n",
       "1   Biogeochemistry (4)       North Carolina (3)                 NC (2)   \n",
       "2         Gull Rock (3)          Swanquarter (3)          Swanquar- (2)   \n",
       "3   Biogeochemistry (4)  the Albemarle Sound (4)                 NC (3)   \n",
       "4        Bhattachan (3)      North  Carolina (3)            Haywood (2)   \n",
       "5          New York (7)             Virginia (7)            Florida (6)   \n",
       "6          HS(cid:1 (4)                    N (4)            Georgia (3)   \n",
       "7        New Jersey (6)     the Delaware Bay (4)             Sebold (4)   \n",
       "8   South Carolina (12)             Georgia (10)           Waccamaw (5)   \n",
       "9              NaCl (6)              Specifi (2)                 MD (2)   \n",
       "10          Niering (8)               Warren (8)               C.R. (7)   \n",
       "11              HUC (4)            Louisiana (3)               Gulf (2)   \n",
       "12  North  Carolina (7)     North Carolina’s (3)                 NC (3)   \n",
       "13             Bird (2)  the Albemarle Sound (1)  the Croatan Sound (1)   \n",
       "14         Maryland (7)               Tester (7)             Kielen (7)   \n",
       "15           Weston (4)       North Carolina (3)                N2O (3)   \n",
       "16         Bridgham (3)       South Carolina (2)           Richmond (2)   \n",
       "17       Louisiana (14)         Mississippi (10)              Texas (8)   \n",
       "\n",
       "                              Col5                     Col6  \\\n",
       "0                                                             \n",
       "1                     Columbia (2)                   MD (2)   \n",
       "2   Palmetto Peartree Preserve (2)                0.01b (2)   \n",
       "3                          L-1 (3)               Ardo´n (2)   \n",
       "4                  Netherlands (2)  the Albemarle Sound (2)   \n",
       "5                New Brunswick (4)              KEARNEY (4)   \n",
       "6                     Canfield (3)               Weston (2)   \n",
       "7                     Delaware (3)              Weishar (3)   \n",
       "8               Waccamaw River (2)           Winyah Bay (2)   \n",
       "9                       NS\\n\\n (2)                NS NS (2)   \n",
       "10                 Connecticut (7)                Smith (4)   \n",
       "11                     Landsat (2)               Akaike (2)   \n",
       "12                   Battaglia (3)        Coastal Plain (3)   \n",
       "13           the Pamlico Sound (1)      the Neuse River (1)   \n",
       "14                       Tanji (6)                   MD (4)   \n",
       "15                  California (2)                Mason (2)   \n",
       "16                    Virginia (2)   the Waccamaw River (2)   \n",
       "17              Gulf of Mexico (8)                   LA (8)   \n",
       "\n",
       "                   Col7  \n",
       "0                        \n",
       "1               N2O (1)  \n",
       "2           Raleigh (1)  \n",
       "3              Ohio (2)  \n",
       "4            ArcGIS (2)  \n",
       "5       Copenheaver (3)  \n",
       "6    Altamaha River (2)  \n",
       "7            Warren (3)  \n",
       "8    Savannah River (2)  \n",
       "9           Purvaja (2)  \n",
       "10             C.S. (4)  \n",
       "11  Charlottesville (1)  \n",
       "12      Liquidambar (3)  \n",
       "13    Blue Grosbeak (1)  \n",
       "14            Qadir (3)  \n",
       "15             Ohio (2)  \n",
       "16   Waccamaw River (2)  \n",
       "17          Alabama (6)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('text_analysis_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
