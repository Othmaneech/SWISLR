{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfminer\n",
    "# !pip install tqdm\n",
    "# !pip install python-time\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boilerplat Function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_file_content(path_to_pdf):\n",
    "    # Set parameters \n",
    "    out_text = StringIO()\n",
    "    text_converter = TextConverter(PDFResourceManager(caching=True), out_text, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(PDFResourceManager(caching=True), text_converter)\n",
    "\n",
    "    fp = open(path_to_pdf, 'rb')\n",
    "\n",
    "    # Set the maximum number of pages to read\n",
    "    max_pages = 5\n",
    "\n",
    "    # Use tqdm to create a progress bar\n",
    "# with tqdm(total=max_pages, desc=\"Extracting\") as pbar:\n",
    "    for index, page in enumerate(PDFPage.get_pages(fp, pagenos=set())):\n",
    "        interpreter.process_page(page)\n",
    "        # pbar.update(1)\n",
    "\n",
    "        # Check if the maximum number of pages has been reached\n",
    "        if index + 1 >= max_pages:\n",
    "            break\n",
    "\n",
    "    text = out_text.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    text_converter.close()\n",
    "    out_text.close()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_most_recurrent_locations(text: str) -> dict:\n",
    "    # Load the pre-trained model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Sample text\n",
    "    sample_text = text\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(sample_text)\n",
    "\n",
    "    # Find location words and their locations\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == \"GPE\" or entity.label_ == \"LOC\"]\n",
    "\n",
    "    # Sorting locations by frequency\n",
    "    my_dict = dict(Counter(locations))\n",
    "    sorted_dict = dict(sorted(my_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    first_five_elements = dict(list(sorted_dict.items())[:5])\n",
    "\n",
    "    return first_five_elements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pdf_file_names():\n",
    "    pdf_files = glob.glob(\"PDF Papers (20)/*.pdf\")\n",
    "    return pdf_files\n",
    "\n",
    "# Define a function to process a single file\n",
    "def process_pdf_file(file):\n",
    "    content = get_pdf_file_content(file)\n",
    "    output_dict = five_most_recurrent_locations(content)\n",
    "    return list(output_dict.keys())\n",
    "\n",
    "pdf_files = get_pdf_file_names()\n",
    "list_of_lists = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multithreading (makes the code run at least 4 times faster!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:20<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create a ThreadPoolExecutor with the maximum number of worker threads\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit the file processing tasks to the executor\n",
    "    future_results = [executor.submit(process_pdf_file, file) for file in pdf_files]\n",
    "\n",
    "    # Use tqdm to track the progress of the tasks\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_results), total=len(future_results)):\n",
    "        # Retrieve the result from the completed task and append it to the list\n",
    "        list_of_lists.append(future.result())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'list_of_lists' now contains the results from processing each PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['North Carolina', 'USA', 'NC', 'Nitrous', 'Megonigal'],\n",
       " ['South Carolina', 'Louisiana', 'Georgia', 'USA', 'Waccamaw'],\n",
       " ['the West Coast', 'Florida', 'USA', 'San Bernardino'],\n",
       " ['North Carolina',\n",
       "  'USA',\n",
       "  'North America',\n",
       "  'Bird',\n",
       "  'United States of America'],\n",
       " ['USA', 'al.', 'Biogeochemistry', 'the Albemarle Sound', 'L-1'],\n",
       " ['USA', 'Weston', 'North Carolina', 'N2O', 'Mason'],\n",
       " ['al.', 'New Jersey', 'Smith', 'al. /', 'the Delaware Bay'],\n",
       " ['al.', 'Georgia', 'the Altamaha River', 'N', 'Weston'],\n",
       " ['al.', 'USA', 'Bridgham', 'South Carolina', 'Richmond'],\n",
       " ['USA', 'North Carolina', 'North  Carolina', 'North Carolina’s', 'NC'],\n",
       " ['al.', 'Florida', 'Louisiana', 'Gulf of Mexico', 'LA'],\n",
       " ['al.', 'USA', 'New England', 'Niering', 'Connecticut'],\n",
       " ['North Carolina', 'Bhattachan', 'USA', 'Netherlands', 'Bhattachan et\\xa0al'],\n",
       " ['USA', 'L-1', 'Biogeochemistry', 'al.', 'North Carolina'],\n",
       " ['al.', 'Maryland', 'Florida', 'Virginia', 'New Brunswick'],\n",
       " ['al.', 'Sorghum', 'Tester', 'Kielen', 'Maryland'],\n",
       " ['HUC', 'USA', 'North America', 'Louisiana', 'North Carolina'],\n",
       " ['NS', 'al.', 'NaCl', 'Specifi', 'MD']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PDF Papers (20)/mcz039.pdf',\n",
       " 'PDF Papers (20)/Journal of Geophysical Research  Biogeosciences - 2006 - Weston - Ramifications of increased salinity in tidal freshwater.pdf',\n",
       " 'PDF Papers (20)/s10533-016-0189-5.pdf',\n",
       " 'PDF Papers (20)/s10021-018-0325-2.pdf',\n",
       " 'PDF Papers (20)/file.pdf',\n",
       " 'PDF Papers (20)/08-77.1.pdf',\n",
       " 'PDF Papers (20)/Journal of Applied Ecology - 2018 - Borchert - Coastal wetland adaptation to sea level rise  Quantifying potential for.pdf',\n",
       " 'PDF Papers (20)/bg-10-8171-2013.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S0006320716303007-main.pdf',\n",
       " 'PDF Papers (20)/s10533-021-00797-5.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S0964569117307676-main.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S009884722030280X-main.pdf',\n",
       " 'PDF Papers (20)/Sea-Level_Rise_and_Coastal_Forest_Retreat_on_the_W.pdf',\n",
       " 'PDF Papers (20)/s10533-014-9986-x.pdf',\n",
       " 'PDF Papers (20)/s11069-019-03706-0.pdf',\n",
       " 'PDF Papers (20)/04-0211.1.pdf',\n",
       " 'PDF Papers (20)/355.Short-Term Response of Carbon Cycling to.pdf',\n",
       " 'PDF Papers (20)/s10021-021-00686-w.pdf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"PDF Papers (20)\" from the strings in pdf_files\n",
    "pdf_files = [file.replace(\"PDF Papers (20)/\", \"\") for file in pdf_files]\n",
    "\n",
    "# Extract the columns from list_of_lists\n",
    "col1 = [item[0] for item in list_of_lists]\n",
    "col2 = [item[1] for item in list_of_lists]\n",
    "col3 = [item[2] for item in list_of_lists]\n",
    "col4 = [item[3] for item in list_of_lists]\n",
    "# col5 = [item[4] for item in list_of_lists]\n",
    "\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'PDF File': pdf_files,\n",
    "    'Col1': col1,\n",
    "    'Col2': col2,\n",
    "    'Col3': col3,\n",
    "    'Col4': col4,\n",
    "    # 'Col5': col5,\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('text_analysis_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
