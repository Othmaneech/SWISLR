{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (20191125)\n",
      "Requirement already satisfied: tqdm in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (4.64.1)\n",
      "Requirement already satisfied: python-time in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: nltk in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: scidownl in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.6.0-cp39-cp39-macosx_10_9_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: pycryptodome in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from pdfminer) (3.18.0)\n",
      "Requirement already satisfied: arrow in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from python-time) (1.2.2)\n",
      "Requirement already satisfied: click in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tablib[cli] in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (3.5.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.10.0 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (4.11.1)\n",
      "Requirement already satisfied: loguru>=0.6.0 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (0.7.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.31 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (1.4.39)\n",
      "Requirement already satisfied: pysocks in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (1.7.1)\n",
      "Requirement already satisfied: wget>=3.2 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (3.2)\n",
      "Requirement already satisfied: setuptools>=58.0.4 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from scidownl) (63.4.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-macosx_10_9_x86_64.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-macosx_10_9_x86_64.whl (492 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from spacy) (5.2.1)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp39-cp39-macosx_10_9_x86_64.whl (867 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.1/867.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.11-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4>=4.10.0->scidownl) (2.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.27.1->scidownl) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.27.1->scidownl) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.27.1->scidownl) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.27.1->scidownl) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy>=1.4.31->scidownl) (1.1.1)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from arrow->python-time) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: tabulate in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from tablib[cli]->scidownl) (0.8.10)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joshmanto/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.0->arrow->python-time) (1.16.0)\n",
      "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, catalogue, blis, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.1.0 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 pydantic-1.10.11 spacy-3.6.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.9.0 wasabi-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer tqdm python-time nltk scidownl spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "from scidownl import scihub_download\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "from scidownl import scihub_download #new addition for scihub unofficial API\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boilerplat Function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_file_content(path_to_pdf):\n",
    "    # Set parameters \n",
    "    out_text = StringIO()\n",
    "    text_converter = TextConverter(PDFResourceManager(caching=True), out_text, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(PDFResourceManager(caching=True), text_converter)\n",
    "\n",
    "    fp = open(path_to_pdf, 'rb')\n",
    "\n",
    "    # Set the maximum number of pages to read\n",
    "    max_pages = 5\n",
    "\n",
    "    # Use tqdm to create a progress bar\n",
    "# with tqdm(total=max_pages, desc=\"Extracting\") as pbar:\n",
    "    for index, page in enumerate(PDFPage.get_pages(fp, pagenos=set())):\n",
    "        interpreter.process_page(page)\n",
    "        # pbar.update(1)\n",
    "\n",
    "        # Check if the maximum number of pages has been reached\n",
    "        if index + 1 >= max_pages:\n",
    "            break\n",
    "\n",
    "    text = out_text.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    text_converter.close()\n",
    "    out_text.close()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_most_recurrent_locations(text: str) -> dict:\n",
    "    # Load the pre-trained model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Sample text\n",
    "    sample_text = text\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(sample_text)\n",
    "\n",
    "    # Find location words and their locations\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == \"GPE\" or entity.label_ == \"LOC\"]\n",
    "\n",
    "    # Sorting locations by frequency\n",
    "    my_dict = dict(Counter(locations))\n",
    "    sorted_dict = dict(sorted(my_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    first_five_elements = dict(list(sorted_dict.items())[:5])\n",
    "\n",
    "    return first_five_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pdf_file_names():\n",
    "    pdf_files = glob.glob(\"PDF Papers (20)/*.pdf\")\n",
    "    return pdf_files\n",
    "\n",
    "# Define a function to process a single file\n",
    "def process_pdf_file(file):\n",
    "    content = get_pdf_file_content(file)\n",
    "    output_dict = five_most_recurrent_locations(content)\n",
    "    return file, list(output_dict.keys())\n",
    "\n",
    "pdf_files = get_pdf_file_names()\n",
    "list_of_lists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multithreading (makes the code run at least 4 times faster!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:20<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "filename = []\n",
    "# Create a ThreadPoolExecutor with the maximum number of worker threads\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit the file processing tasks to the executor\n",
    "    future_results = [executor.submit(process_pdf_file, file) for file in pdf_files]\n",
    "\n",
    "    # Use tqdm to track the progress of the tasks\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_results), total=len(future_results)):\n",
    "        # Retrieve the result from the completed task and append it to the list\n",
    "        list_of_lists.append(future.result()[1])\n",
    "        filename.append(future.result()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'list_of_lists' now contains the results from processing each PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['North Carolina',\n",
       "  'USA',\n",
       "  'North America',\n",
       "  'Bird',\n",
       "  'United States of America'],\n",
       " ['North Carolina', 'USA', 'NC', 'Nitrous', 'Megonigal'],\n",
       " ['the West Coast', 'Florida', 'USA', 'San Bernardino'],\n",
       " ['USA', 'al.', 'Biogeochemistry', 'the Albemarle Sound', 'L-1'],\n",
       " ['South Carolina', 'Louisiana', 'Georgia', 'USA', 'Waccamaw'],\n",
       " ['USA', 'Weston', 'North Carolina', 'N2O', 'Mason'],\n",
       " ['al.', 'Georgia', 'the Altamaha River', 'N', 'Weston'],\n",
       " ['al.', 'New Jersey', 'Smith', 'al. /', 'the Delaware Bay'],\n",
       " ['al.', 'USA', 'Bridgham', 'South Carolina', 'Richmond'],\n",
       " ['USA', 'North Carolina', 'North  Carolina', 'North Carolina’s', 'NC'],\n",
       " ['al.', 'USA', 'New England', 'Niering', 'Connecticut'],\n",
       " ['North Carolina', 'Bhattachan', 'USA', 'Netherlands', 'Bhattachan et\\xa0al'],\n",
       " ['al.', 'Florida', 'Louisiana', 'Gulf of Mexico', 'LA'],\n",
       " ['al.', 'Sorghum', 'Tester', 'Kielen', 'Maryland'],\n",
       " ['USA', 'L-1', 'Biogeochemistry', 'al.', 'North Carolina'],\n",
       " ['al.', 'Maryland', 'Florida', 'Virginia', 'New Brunswick'],\n",
       " ['HUC', 'USA', 'North America', 'Louisiana', 'North Carolina'],\n",
       " ['NS', 'al.', 'NaCl', 'Specifi', 'MD']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PDF Papers (20)/mcz039.pdf',\n",
       " 'PDF Papers (20)/Journal of Geophysical Research  Biogeosciences - 2006 - Weston - Ramifications of increased salinity in tidal freshwater.pdf',\n",
       " 'PDF Papers (20)/s10533-016-0189-5.pdf',\n",
       " 'PDF Papers (20)/s10021-018-0325-2.pdf',\n",
       " 'PDF Papers (20)/file.pdf',\n",
       " 'PDF Papers (20)/08-77.1.pdf',\n",
       " 'PDF Papers (20)/Journal of Applied Ecology - 2018 - Borchert - Coastal wetland adaptation to sea level rise  Quantifying potential for.pdf',\n",
       " 'PDF Papers (20)/bg-10-8171-2013.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S0006320716303007-main.pdf',\n",
       " 'PDF Papers (20)/s10533-021-00797-5.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S0964569117307676-main.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S009884722030280X-main.pdf',\n",
       " 'PDF Papers (20)/Sea-Level_Rise_and_Coastal_Forest_Retreat_on_the_W.pdf',\n",
       " 'PDF Papers (20)/s10533-014-9986-x.pdf',\n",
       " 'PDF Papers (20)/s11069-019-03706-0.pdf',\n",
       " 'PDF Papers (20)/04-0211.1.pdf',\n",
       " 'PDF Papers (20)/355.Short-Term Response of Carbon Cycling to.pdf',\n",
       " 'PDF Papers (20)/s10021-021-00686-w.pdf']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PDF Papers (20)/file.pdf',\n",
       " 'PDF Papers (20)/s10533-021-00797-5.pdf',\n",
       " 'PDF Papers (20)/Sea-Level_Rise_and_Coastal_Forest_Retreat_on_the_W.pdf',\n",
       " 'PDF Papers (20)/s10533-016-0189-5.pdf',\n",
       " 'PDF Papers (20)/08-77.1.pdf',\n",
       " 'PDF Papers (20)/s10021-018-0325-2.pdf',\n",
       " 'PDF Papers (20)/Journal of Geophysical Research  Biogeosciences - 2006 - Weston - Ramifications of increased salinity in tidal freshwater.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S0964569117307676-main.pdf',\n",
       " 'PDF Papers (20)/bg-10-8171-2013.pdf',\n",
       " 'PDF Papers (20)/mcz039.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S0006320716303007-main.pdf',\n",
       " 'PDF Papers (20)/s11069-019-03706-0.pdf',\n",
       " 'PDF Papers (20)/Journal of Applied Ecology - 2018 - Borchert - Coastal wetland adaptation to sea level rise  Quantifying potential for.pdf',\n",
       " 'PDF Papers (20)/1-s2.0-S009884722030280X-main.pdf',\n",
       " 'PDF Papers (20)/s10533-014-9986-x.pdf',\n",
       " 'PDF Papers (20)/04-0211.1.pdf',\n",
       " 'PDF Papers (20)/s10021-021-00686-w.pdf',\n",
       " 'PDF Papers (20)/355.Short-Term Response of Carbon Cycling to.pdf']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"PDF Papers (20)\" from the strings in pdf_files\n",
    "filename = [file.replace(\"PDF Papers (20)/\", \"\") for file in filename]\n",
    "\n",
    "# Extract the columns from list_of_lists\n",
    "col1 = [item[0] for item in list_of_lists]\n",
    "col2 = [item[1] for item in list_of_lists]\n",
    "col3 = [item[2] for item in list_of_lists]\n",
    "col4 = [item[3] for item in list_of_lists]\n",
    "# col5 = [item[4] for item in list_of_lists]\n",
    "\n",
    "\n",
    "# Create the dataframe\n",
    "data = {\n",
    "    'PDF File': filename,\n",
    "    'Col1': col1,\n",
    "    'Col2': col2,\n",
    "    'Col3': col3,\n",
    "    'Col4': col4,\n",
    "    # 'Col5': col5,\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('text_analysis_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['North Carolina',\n",
       "  'USA',\n",
       "  'North America',\n",
       "  'Bird',\n",
       "  'United States of America'],\n",
       " ['North Carolina', 'USA', 'NC', 'Nitrous', 'Megonigal'],\n",
       " ['the West Coast', 'Florida', 'USA', 'San Bernardino'],\n",
       " ['USA', 'al.', 'Biogeochemistry', 'the Albemarle Sound', 'L-1'],\n",
       " ['South Carolina', 'Louisiana', 'Georgia', 'USA', 'Waccamaw'],\n",
       " ['USA', 'Weston', 'North Carolina', 'N2O', 'Mason'],\n",
       " ['al.', 'Georgia', 'the Altamaha River', 'N', 'Weston'],\n",
       " ['al.', 'New Jersey', 'Smith', 'al. /', 'the Delaware Bay'],\n",
       " ['al.', 'USA', 'Bridgham', 'South Carolina', 'Richmond'],\n",
       " ['USA', 'North Carolina', 'North  Carolina', 'North Carolina’s', 'NC'],\n",
       " ['al.', 'USA', 'New England', 'Niering', 'Connecticut'],\n",
       " ['North Carolina', 'Bhattachan', 'USA', 'Netherlands', 'Bhattachan et\\xa0al'],\n",
       " ['al.', 'Florida', 'Louisiana', 'Gulf of Mexico', 'LA'],\n",
       " ['al.', 'Sorghum', 'Tester', 'Kielen', 'Maryland'],\n",
       " ['USA', 'L-1', 'Biogeochemistry', 'al.', 'North Carolina'],\n",
       " ['al.', 'Maryland', 'Florida', 'Virginia', 'New Brunswick'],\n",
       " ['HUC', 'USA', 'North America', 'Louisiana', 'North Carolina'],\n",
       " ['NS', 'al.', 'NaCl', 'Specifi', 'MD']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
