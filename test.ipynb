{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# Set your keywords\n",
    "my_input = 'salinization AND flooding'\n",
    "# Set your API Key\n",
    "key = 'a4dfe1b4f9535e6e41587a40f9ba9877'\n",
    "\n",
    "# Create a session for making requests\n",
    "session = requests.Session()\n",
    "session.headers['X-ELS-APIKey'] = key\n",
    "session.headers['X-ELS-ResourceVersion'] = 'XOCS'\n",
    "session.headers['Accept'] = 'application/json'\n",
    "\n",
    "def scopus_search(my_input: str) -> list:\n",
    "    api_resource = \"https://api.elsevier.com/content/search/scopus?\"\n",
    "    search_param = f'query=title-abs-key({my_input})'  # for example\n",
    "\n",
    "    # Set the desired number of results per page\n",
    "    results_per_page = 25\n",
    "\n",
    "    # Send the first request to get the total number of results\n",
    "    first_page_request = session.get(api_resource + search_param + f\"&count={results_per_page}&start=0\")\n",
    "    first_page = json.loads(first_page_request.content.decode(\"utf-8\"))\n",
    "\n",
    "    total_results = int(first_page['search-results']['opensearch:totalResults'])\n",
    "    total_pages = (total_results // results_per_page) + 1\n",
    "\n",
    "    # List to store all articles\n",
    "    articles_list = []\n",
    "\n",
    "    print(f\"Scrapping Data Pages from Scopus using {my_input}...\")\n",
    "    # Iterate over all pages\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for page_number in tqdm(range(total_pages)):\n",
    "            start_index = page_number * results_per_page\n",
    "            page_request = session.get(api_resource + search_param + f\"&count={results_per_page}&start={start_index}\")\n",
    "            page = json.loads(page_request.content.decode(\"utf-8\"))\n",
    "            try:\n",
    "                articles_list.extend(page['search-results']['entry'])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(f\"Number of articles: {len(articles_list)}\")\n",
    "        return articles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "article_title = []\n",
    "article_doi = []\n",
    "article_eid = []\n",
    "article_ID = []\n",
    "article_pii = []\n",
    "article_url = []\n",
    "article_lead= []\n",
    "article_pub = []\n",
    "article_coverDate = []\n",
    "\n",
    "# Access individual articles\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for article in tqdm(range(len(articles_list))):\n",
    "        try:\n",
    "            article_pii.append(articles_list[article].get(\"pii\"))\n",
    "            article_title.append(articles_list[article].get(\"dc:title\"))\n",
    "            article_doi.append(articles_list[article].get(\"prism:doi\"))\n",
    "            article_eid.append(articles_list[article].get(\"eid\"))\n",
    "            article_ID.append(articles_list[article].get(\"dc:identifier\"))\n",
    "            article_url.append(articles_list[article].get(\"prism:url\"))\n",
    "            article_lead.append(articles_list[article].get(\"dc:creator\"))\n",
    "            article_pub.append(articles_list[article].get(\"prism:publicationName\"))\n",
    "            article_coverDate.append(articles_list[article].get(\"prism:coverDate\"))\n",
    "\n",
    "        except:\n",
    "            article_pii.append(None)\n",
    "            article_doi.append(None)\n",
    "            article_title.append(articles_list[article].get(\"dc:title\"))\n",
    "            article_eid.append(articles_list[article].get(\"eid\"))\n",
    "            article_ID.append(articles_list[article].get(\"dc:identifier\"))\n",
    "            article_url.append(articles_list[article].get(\"prism:url\"))\n",
    "            article_lead.append(None)\n",
    "            article_pub.append(articles_list[article].get(\"prism:publicationName\"))\n",
    "            article_coverDate.append(articles_list[article].get(\"prism:coverDate\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scopus_id_abstract_retriever(scopus_id: str) -> str:\n",
    "    api_endpoint = f\"https://api.elsevier.com/content/abstract/scopus_id/{scopus_id}\"\n",
    "\n",
    "    # Make the request to retrieve the abstract\n",
    "    response = session.get(api_endpoint)\n",
    "    data = json.loads(response.content.decode(\"utf-8\"))\n",
    "    # Extract the abstract from the response\n",
    "    try:\n",
    "        abstract = data[\"abstracts-retrieval-response\"][\"coredata\"][\"dc:description\"]\n",
    "        affiliation = data[\"abstracts-retrieval-response\"][\"affiliation\"]['affilname']\n",
    "        # Study Area\n",
    "        area = data[\"abstracts-retrieval-response\"][\"subject-areas\"][\"subject-area\"]\n",
    "        subjects = [subject[\"$\"] for subject in area]\n",
    "        result = \" & \".join(subjects)\n",
    "        # Authors\n",
    "        author_count = len(data[\"abstracts-retrieval-response\"][\"authors\"]['author'])\n",
    "\n",
    "    except:\n",
    "        abstract = \"NA\"\n",
    "        affiliation = data[\"abstracts-retrieval-response\"][\"affiliation\"]['affilname']\n",
    "        # Study Area\n",
    "        area = data[\"abstracts-retrieval-response\"][\"subject-areas\"][\"subject-area\"]\n",
    "        subjects = [subject[\"$\"] for subject in area]\n",
    "        result = \" & \".join(subjects)\n",
    "        # Authors\n",
    "        author_count = len(data[\"abstracts-retrieval-response\"][\"authors\"]['author'])\n",
    "\n",
    "\n",
    "    # Return the abstract\n",
    "    return abstract, affiliation, result, author_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Saline-alkali land, a precious candidate arable land resources, plays a critical role in achieving agricultural sustainability. Drip irrigation (DI) is an effective method for rationalizing of saline-alkali land. Nevertheless, the inapposite application of DI increases the risk of secondary salinization, significantly leading to severe soil degradation and yield decline. In this study, we conducted a meta-analysis to quantify the impacts of DI on soil salinity and crop yield to determine the appropriate DI management strategies for an irrigated agricultural system in saline-alkali land. The results showed that DI generally decreased soil salinity in the root zone by 37.7 % and increased crop yield by 37.4 % relative to flooding irrigation (FI). Drip emitters with a flow rate of 2–4 L h−1 were recommended to obtain positive effects on soil salinity control and agricultural production when an irrigation quota was below 50 % crop evapotranspiration (ETc), and the salinity of irrigation water was between 0.7 and 2 dS m−1. Further, we also found that drip-irrigated cotton had a higher yield on fine-textured saline soils. Our study provides scientific recommendations for applying DI technology worldwide in the saline-alkali land.',\n",
       " 'Northwest A&amp;F University',\n",
       " 'Environmental Engineering & Environmental Chemistry & Waste Management and Disposal & Pollution',\n",
       " 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scopus_id_abstract_retriever(\"SCOPUS_ID:85151557628\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
